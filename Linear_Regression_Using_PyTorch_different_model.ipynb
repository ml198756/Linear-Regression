{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict (before training) 4 21.0\n",
      "Epoch 0: w1 = -0.01927196979522705, w2 = 0.6087759733200073, b = 0.8371919989585876, Loss = 18.321826934814453\n",
      "Epoch 10: w1 = 0.2856519818305969, w2 = 0.7844908833503723, b = 0.937275230884552, Loss = 0.02848036028444767\n",
      "Epoch 20: w1 = 0.27328190207481384, w2 = 0.8200692534446716, b = 0.9667862057685852, Loss = 0.019148115068674088\n",
      "Epoch 30: w1 = 0.2643830478191376, w2 = 0.8460506796836853, b = 0.9847812652587891, Loss = 0.014172340743243694\n",
      "Epoch 40: w1 = 0.2579308748245239, w2 = 0.8655898571014404, b = 0.9950385093688965, Loss = 0.011208509095013142\n",
      "Epoch 50: w1 = 0.25313133001327515, w2 = 0.8807737827301025, b = 1.000089168548584, Loss = 0.00937769003212452\n",
      "Epoch 60: w1 = 0.24944846332073212, w2 = 0.8930094838142395, b = 1.0016393661499023, Loss = 0.00820931326597929\n",
      "Epoch 70: w1 = 0.24652099609375, w2 = 0.9032458066940308, b = 1.0008395910263062, Loss = 0.007440924644470215\n",
      "Epoch 80: w1 = 0.24410557746887207, w2 = 0.9121231436729431, b = 0.9984659552574158, Loss = 0.006920332089066505\n",
      "Epoch 90: w1 = 0.2420377880334854, w2 = 0.9200724959373474, b = 0.9950411319732666, Loss = 0.0065572685562074184\n",
      "Predict (after training) 4 8.544171333312988\n",
      "Final parameters: w1 = 0.24038191139698029, w2 = 0.9266766309738159, b = 0.99135422706604\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 数据\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "# 初始化权重和偏置\n",
    "w1 = torch.tensor([1.0], requires_grad=True)\n",
    "w2 = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# 定义模型的前向传播\n",
    "def forward(x):\n",
    "    return w1 * x ** 2 + w2 * x + b\n",
    "\n",
    "# 定义损失函数\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) ** 2\n",
    "\n",
    "# 训练前的预测\n",
    "print(\"Predict (before training)\", 4, forward(4).item())\n",
    "\n",
    "# 训练过程\n",
    "learning_rate = 0.01\n",
    "for epoch in range(100):\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        l = loss(x, y)\n",
    "        l.backward()\n",
    "        with torch.no_grad():\n",
    "            w1 -= learning_rate * w1.grad\n",
    "            w2 -= learning_rate * w2.grad\n",
    "            b -= learning_rate * b.grad\n",
    "\n",
    "            # 清零累积的梯度\n",
    "            w1.grad.zero_()\n",
    "            w2.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0: # 每10个epoch打印一次\n",
    "        print(f\"Epoch {epoch}: w1 = {w1.item()}, w2 = {w2.item()}, b = {b.item()}, Loss = {l.item()}\")\n",
    "\n",
    "# 训练后的预测\n",
    "print(\"Predict (after training)\", 4, forward(4).item())\n",
    "\n",
    "# 打印最终的参数值\n",
    "print(f\"Final parameters: w1 = {w1.item()}, w2 = {w2.item()}, b = {b.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
